<!DOCTYPE html>
<html lang="en-us"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.46">
  <meta name="author" content="Jacob Buckman">

  
  
  
  
    
  
  <meta name="description" content="This post is the first of a series; click here for the next post, or here for a list of all posts in this series.
Click here to skip the intro and dive right in!
Introduction What is this? Who are you? I’m Jacob, a Google AI Resident. When I started the residency program in the summer of 2017, I had a lot of experience programming, and a good understanding of machine learning, but I had never used Tensorflow before.">

  
  <link rel="alternate" hreflang="en-us" href="https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/">

  


  

  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  
    
    <link rel="stylesheet" href="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/bootstrap.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
    <link rel="stylesheet" href="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/academicons.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/font-awesome.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
    <link rel="stylesheet" href="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/jquery.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/github.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/css.css">
  

  <link rel="stylesheet" href="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/styles.css">
  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-62746966-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async="" src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/analytics.js"></script>
    
    <script async="" src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  
  <link rel="alternate" href="https://jacobbuckman.com/index.xml" type="application/rss+xml" title="Buckman's Homepage">
  <link rel="feed" href="https://jacobbuckman.com/index.xml" type="application/rss+xml" title="Buckman's Homepage">
  

  <link rel="manifest" href="http://jacobbuckman.com/site.webmanifest">
  <link rel="icon" type="image/png" href="http://jacobbuckman.com/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="http://jacobbuckman.com/img/icon-192.png">

  <link rel="canonical" href="https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@jacobmbuckman">
  <meta property="twitter:creator" content="@jacobmbuckman">
  
  <meta property="og:site_name" content="Buckman's Homepage">
  <meta property="og:url" content="https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/">
  <meta property="og:title" content="Tensorflow: The Confusing Parts (1) | Buckman's Homepage">
  <meta property="og:description" content="This post is the first of a series; click here for the next post, or here for a list of all posts in this series.
Click here to skip the intro and dive right in!
Introduction What is this? Who are you? I’m Jacob, a Google AI Resident. When I started the residency program in the summer of 2017, I had a lot of experience programming, and a good understanding of machine learning, but I had never used Tensorflow before.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-06-25T14:53:44+00:00">
  
  <meta property="article:modified_time" content="2018-06-25T14:53:44+00:00">
  

  

<link rel="stylesheet" href="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/cookieconsent.css">
<script src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/cookieconsent.js"></script>
<script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#3f51b5",
          "text": "#fff"
        },
        "button": {
          "background": "#fff",
          "text": "#3f51b5"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "https://cookies.insites.com"
      }
    })});
</script>


  

  <title>Tensorflow: The Confusing Parts (1) | Buckman's Homepage</title>

<script async="" src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/embed.js" data-timestamp="1540324724250"></script><script src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/count-data.js"></script><link rel="prefetch" as="style" href="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/a_data/lounge.css"><link rel="prefetch" as="script" href="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/a_data/common.js"><link rel="prefetch" as="script" href="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/a_data/lounge_002.js"><link rel="prefetch" as="script" href="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/a_data/config.js"><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1px; bottom: 2px; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-chartest {display: block; visibility: hidden; position: absolute; top: 0; line-height: normal; font-size: 500%}
.mjx-chartest .mjx-char {display: inline}
.mjx-chartest .mjx-box {padding-top: 1000px}
.MJXc-processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MJXc-processed {display: none}
.mjx-test {display: block; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow: hidden; height: 1px}
.mjx-ex-box-test {position: absolute; overflow: hidden; width: 1px; height: 60ex}
.mjx-line-box-test {display: table!important}
.mjx-line-box-test span {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
#MathJax_CHTML_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.mjx-chtml .mjx-noError {line-height: 1.2; vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
.MJXc-TeX-unknown-R {font-family: STIXGeneral,'Cambria Math','Arial Unicode MS',serif; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: STIXGeneral,'Cambria Math','Arial Unicode MS',serif; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: STIXGeneral,'Cambria Math','Arial Unicode MS',serif; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: STIXGeneral,'Cambria Math','Arial Unicode MS',serif; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><style></style><script src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/alfalfa.js" async="" charset="UTF-8"></script></head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71"><div role="dialog" aria-live="polite" aria-label="cookieconsent" aria-describedby="cookieconsent:desc" class="cc-window cc-banner cc-type-info cc-theme-classic cc-bottom cc-color-override-589294378 " style=""><!--googleoff: all--><span id="cookieconsent:desc" class="cc-message">This website uses cookies to ensure you get the best experience on our website. <a aria-label="learn more about cookies" role="button" tabindex="0" class="cc-link" href="https://cookies.insites.com/" target="_blank">Learn more</a></span><div class="cc-compliance"><a aria-label="dismiss cookie message" role="button" tabindex="0" class="cc-btn cc-dismiss">Got it!</a></div><!--googleon: all--></div><div id="MathJax_Message" style="display: none;"></div>

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="http://jacobbuckman.com/">Buckman's Homepage</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="http://jacobbuckman.com/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="http://jacobbuckman.com/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="http://jacobbuckman.com/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope="" itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Tensorflow: The Confusing Parts (1)</h1>

    

<div class="article-metadata">

  
  
  
  <div>
    
    <span itemscope="" itemprop="author" itemtype="http://schema.org/Person">
      <span itemprop="name">Jacob Buckman</span>
    </span>
    
  </div>
  

  <span class="article-date">
    
    <meta content="2018-06-25 14:53:44 +0000 UTC" itemprop="datePublished">
    <time datetime="2018-06-25 14:53:44 +0000 UTC" itemprop="dateModified">
      Jun 25, 2018
    </time>
  </span>
  <span itemscope="" itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Jacob Buckman">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    21 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/#disqus_thread">20 Comments</a>
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fa fa-folder"></i>
    
    <a href="https://jacobbuckman.com/categories/tutorial/">Tutorial</a>, 
    
    <a href="https://jacobbuckman.com/categories/tftcp/">TFTCP</a>
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter" href="https://twitter.com/intent/tweet?text=Tensorflow%3a%20The%20Confusing%20Parts%20%281%29&amp;url=https%3a%2f%2fjacobbuckman.com%2fpost%2ftensorflow-the-confusing-parts-1%2f" target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fjacobbuckman.com%2fpost%2ftensorflow-the-confusing-parts-1%2f" target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fjacobbuckman.com%2fpost%2ftensorflow-the-confusing-parts-1%2f&amp;title=Tensorflow%3a%20The%20Confusing%20Parts%20%281%29" target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo" href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fjacobbuckman.com%2fpost%2ftensorflow-the-confusing-parts-1%2f&amp;title=Tensorflow%3a%20The%20Confusing%20Parts%20%281%29" target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email" href="mailto:?subject=Tensorflow%3a%20The%20Confusing%20Parts%20%281%29&amp;body=https%3a%2f%2fjacobbuckman.com%2fpost%2ftensorflow-the-confusing-parts-1%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


    <div class="article-style" itemprop="articleBody">
      

<p><em>This post is the first of a series; click <a href="https://jacobbuckman.com/post/tensorflow-the-confusing-parts-2/" target="_blank">here</a> for the next post, or <a href="https://jacobbuckman.com/categories/tftcp/" target="_blank">here</a> for a list of all posts in this series.</em></p>

<p><a href="#understanding-tensorflow">Click here to skip the intro and dive right in!</a></p>

<h1 id="introduction">Introduction</h1>

<h3 id="what-is-this-who-are-you">What is this? Who are you?</h3>

<p>I’m Jacob, a <a href="https://ai.google/research/join-us/ai-residency/" target="_blank">Google AI Resident</a>.
 When I started the residency program in the summer of 2017, I had a lot
 of experience programming, and a good understanding of machine 
learning, but I had never used Tensorflow before. I figured that given 
my background I’d be able to pick it up quickly.  To my surprise, the 
learning curve was fairly steep, and even months into the residency, I 
would occasionally find myself confused about how to turn ideas into 
Tensorflow code. I’m writing this blog post as a message-in-a-bottle to 
my former self: it’s the introduction that I wish I had been given 
before starting on my journey. Hopefully, it will also be a helpful 
resource for others.</p>

<h3 id="what-was-missing">What was missing?</h3>

<p>In the three years since its release, <a href="https://github.com/thedataincubator/data-science-blogs/blob/master/output/DL_libraries_final_Rankings.csv" target="_blank">Tensorflow has cemented itself as a cornerstone of the deep learning ecosystem</a>. However, it can be non-intuitive for beginners, especially compared to define-by-run<sup class="footnote-ref" id="fnref:0"><a href="#fn:0">1</a></sup> neural network libraries like <a href="https://pytorch.org/" target="_blank">PyTorch</a> or <a href="http://dynet.io/" target="_blank">DyNet</a>.</p>

<p>Many introductory Tensorflow tutorials exist, for doing everything from <a href="https://www.tensorflow.org/tutorials/wide" target="_blank">linear regression</a>, to <a href="https://www.tensorflow.org/tutorials/layers" target="_blank">classifying MNIST</a>, to <a href="https://www.tensorflow.org/tutorials/seq2seq" target="_blank">machine translation</a>.
 These concrete, practical guides are great resources for getting 
Tensorflow projects up and running, and can serve as jumping-off points 
for similar projects. But for the people who are working on applications
 for which a good tutorial does not exist, or who want to do something 
totally off the beaten path (as is common in research), Tensorflow can 
definitely feel frustrating at first.</p>

<p>This post is my attempt to fill this gap. Rather than focusing on a 
specific task, I take a more general approach, and explain the 
fundamental abstractions underpinning Tensorflow. With a good grasp of 
these concepts, deep learning with Tensorflow becomes intuitive and 
straightforward.</p>

<h3 id="target-audience">Target Audience</h3>

<p>This tutorial is intended for people who already have some experience
 with both programming and machine learning, and want to pick up 
Tensorflow. For example: a computer science student who wants to use 
Tensorflow in the final project of her ML class; a software engineer who
 has just been assigned to a project that involves deep learning; or a 
bewildered new Google AI Resident (shout-out to past Jacob). If you’d 
like a refresher on the basics, <a href="https://ml.berkeley.edu/blog/2016/11/06/tutorial-1/" target="_blank">here</a> <a href="http://colah.github.io/" target="_blank">are</a> <a href="https://www.udacity.com/course/intro-to-machine-learning--ud120" target="_blank">some</a> <a href="https://www.coursera.org/learn/machine-learning" target="_blank">resources</a>. Otherwise: let’s get started!</p>

<hr>

<h1 id="understanding-tensorflow">Understanding Tensorflow</h1>

<h3 id="tensorflow-is-not-a-normal-python-library">Tensorflow Is Not A Normal Python Library</h3>

<p>Most Python libraries are written to be natural extensions of Python.
 When you import a library, what you get is a set of variables, 
functions, and classes, that augment and complement your “toolbox” of 
code. When using them, you have a certain set of expectations about how 
they behave. In my opinion, when it comes to Tensorflow, you should 
throw all that away. It’s fundamentally the wrong way to think about 
what Tensorflow is and how it interacts with the rest of your code.</p>

<p>A metaphor for the relationship between Python and Tensorflow is the 
relationship between Javascript and HTML. Javascript is a fully-featured
 programming language that can do all sorts of wonderful things. HTML is
 a framework for representing a certain type of useful computational 
abstraction (in this case, content that can be rendered by a web 
browser). The role of Javascript in an interactive webpage is to 
assemble the HTML object that the browser sees, and then interact with 
it when necessary by updating it to new HTML.</p>

<p>Similarly to HTML, Tensorflow is a framework for representing a 
certain type of computational abstraction (known as “computation 
graphs”). When we manipulate Tensorflow with Python, the first thing we 
do with our Python code is assemble the computation graph. Once that is 
done, the second thing we do is to interact with it (using Tensorflow’s 
“sessions”). But it’s important to keep in mind that the computation 
graph does not live inside of your variables; it lives in the global 
namespace. As Shakespeare once said: “All the RAM’s a stage, and all the
 variables are merely pointers.”</p>

<h3 id="first-key-abstraction-the-computation-graph">First Key Abstraction: The Computation Graph</h3>

<p>In browsing the Tensorflow documentation, you’ve probably found 
oblique references to “graphs” and “nodes”. If you’re a particularly 
savvy browser, you may have even discovered <a href="https://www.tensorflow.org/programmers_guide/graphs" target="_blank">this page</a>,
 which covers the content I’m about to explain in a much more accurate 
and technical fashion. This section is a high-level walkthrough that 
captures the important intuition, while sacrificing some technical 
details.</p>

<p>So: what is a computation graph? Essentially, it’s a global data 
structure: a directed graph that captures instructions about how to 
calculate things.</p>

<p>Let’s walk through an example of how to build one. In the following 
figures, the top half is the code we ran and its output, and the bottom 
half is the resulting computation graph.</p>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
</code></pre>

<h6 id="graph">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig0.png" width="300px">


</figure>

<p>Predictably, just importing Tensorflow does not give us an 
interesting computation graph. Just a lonely, empty global variable. But
 what about when we call a Tensorflow operation?</p>

<h6 id="code">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
two_node = tf.constant(<span class="hljs-number">2</span>)
<span class="hljs-keyword">print</span> two_node
</code></pre>

<h6 id="output">Output:</h6>

<pre><code class="language-python hljs">Tensor(<span class="hljs-string">"Const:0"</span>, shape=(), dtype=int32)
</code></pre>

<h6 id="graph-1">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig1.png" width="300px">


</figure>

<p>Would you look at that! We got ourselves a node. It contains the constant 2. Shocking, I know, coming from a function called <code>tf.constant</code>. When we print the variable, we see that it returns a <code>tf.Tensor</code> object, which is a pointer to the node that we just created. To emphasize this, here’s another example:</p>

<h6 id="code-1">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
two_node = tf.constant(<span class="hljs-number">2</span>)
another_two_node = tf.constant(<span class="hljs-number">2</span>)
two_node = tf.constant(<span class="hljs-number">2</span>)
tf.constant(<span class="hljs-number">3</span>)
</code></pre>

<h6 id="graph-2">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig2.png" width="300px">


</figure>

<p>Every time we call <code>tf.constant</code>, we create a new node in 
the graph. This is true even if the node is functionally identical to an
 existing node, even if we re-assign a node to the same variable, or  
even if we don’t assign it to a variable at all.</p>

<p>In contrast, if you make a new variable and set it equal to an 
existing node, you are just copying the pointer to that node and nothing
 is added to the graph:</p>

<h6 id="code-2">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
two_node = tf.constant(<span class="hljs-number">2</span>)
another_pointer_at_two_node = two_node
two_node = <span class="hljs-keyword">None</span>
<span class="hljs-keyword">print</span> two_node
<span class="hljs-keyword">print</span> another_pointer_at_two_node
</code></pre>

<h6 id="output-1">Output:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">None</span>
Tensor(<span class="hljs-string">"Const:0"</span>, shape=(), dtype=int32)
</code></pre>

<h6 id="graph-3">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig3.png" width="300px">


</figure>

<p>Okay, let’s liven things up a bit:</p>

<h6 id="code-3">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
two_node = tf.constant(<span class="hljs-number">2</span>)
three_node = tf.constant(<span class="hljs-number">3</span>)
sum_node = two_node + three_node <span class="hljs-comment">## equivalent to tf.add(two_node, three_node)</span>
</code></pre>

<h6 id="graph-4">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig4.png" width="300px">


</figure>

<p>Now we’re talking - that’s a bona-fide computational graph we got there! Notice that the <code>+</code>
 operation is overloaded in Tensorflow, so adding two tensors together 
adds a node to the graph, even though it doesn’t seem like a Tensorflow 
operation on the surface.</p>

<p>Okay, so <code>two_node</code> points to a node containing 2, <code>three_node</code> points to a node containing 3, and <code>sum_node</code> points to a node containing…<code>+</code>? What’s up with that? Shouldn’t it contain 5?</p>

<p>As it turns out, no. Computational graphs contain only the steps of 
computation; they do not contain the results. At least…not yet!</p>

<h3 id="second-key-abstraction-the-session">Second Key Abstraction: The Session</h3>

<p>If there were March Madness for misunderstood TensorFlow 
abstractions, the session would be the #1 seed every year. It has that 
dubious honor due to being both unintuitively named and universally 
present – nearly every Tensorflow program explicitly invokes <code>tf.Session()</code> at least once.</p>

<p>The role of the session is to handle the memory allocation and 
optimization that allows us to actually perform the computations 
specified by a graph. You can think of the computation graph as a 
“template” for the computations we want to do: it lays out all the 
steps. In order to make use of the graph, we also need to make a 
session, which allows us to actually do things; for example, going 
through the template node-by-node to allocate a bunch of memory for 
storing computation outputs. In order to do any computation with 
Tensorflow, you need both a graph and a session.</p>

<p>The session contains a pointer to the global graph, which is 
constantly updated with pointers to all nodes. That means it doesn’t 
really matter whether you create the session before or after you create 
the nodes. <sup class="footnote-ref" id="fnref:1"><a href="#fn:1">2</a></sup></p>

<p>After creating your session object, you can use <code>sess.run(node)</code> to return the value of a node, and Tensorflow performs all computations necessary to determine that value.</p>

<h6 id="code-4">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
two_node = tf.constant(<span class="hljs-number">2</span>)
three_node = tf.constant(<span class="hljs-number">3</span>)
sum_node = two_node + three_node
sess = tf.Session()
<span class="hljs-keyword">print</span> sess.run(sum_node)
</code></pre>

<h6 id="output-2">Output:</h6>

<pre><code class="language-python hljs"><span class="hljs-number">5</span>
</code></pre>

<h6 id="graph-5">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig4.png" width="300px">


</figure>

<p>Wonderful! We can also pass a list, <code>sess.run([node1, node2,...])</code>, and have it return multiple outputs:</p>

<h6 id="code-5">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
two_node = tf.constant(<span class="hljs-number">2</span>)
three_node = tf.constant(<span class="hljs-number">3</span>)
sum_node = two_node + three_node
sess = tf.Session()
<span class="hljs-keyword">print</span> sess.run([two_node, sum_node])
</code></pre>

<h6 id="output-3">Output:</h6>

<pre><code class="language-python hljs">[<span class="hljs-number">2</span>, <span class="hljs-number">5</span>]
</code></pre>

<h6 id="graph-6">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig4.png" width="300px">


</figure>

<p>In general, <code>sess.run()</code> calls tend to be one of the 
biggest TensorFlow bottlenecks, so the fewer times you call it, the 
better. Whenever possible, return multiple items in a single <code>sess.run()</code> call instead of making multiple calls.</p>

<h3 id="placeholders-feed-dict">Placeholders &amp; feed_dict</h3>

<p>The computations we’ve done so far have been boring: there is no 
opportunity to pass in input, so they always output the same thing. A 
more worthwhile application might involve constructing a computation 
graph that takes in input, processes it in some (consistent) way, and 
returns an output.</p>

<p>The most straightforward way to do this is with placeholders. A 
placeholder is a type of node that is designed to accept external input.</p>

<h6 id="code-6">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
input_placeholder = tf.placeholder(tf.int32)
sess = tf.Session()
<span class="hljs-keyword">print</span> sess.run(input_placeholder)
</code></pre>

<h6 id="output-4">Output:</h6>

<pre><code class="language-python hljs">Traceback (most recent call last):
...
InvalidArgumentError (see above <span class="hljs-keyword">for</span> traceback): You must feed a value <span class="hljs-keyword">for</span> placeholder tensor <span class="hljs-string">'Placeholder'</span> <span class="hljs-keyword">with</span> dtype int32
	 [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=&lt;unknown&gt;, _device=<span class="hljs-string">"/job:localhost/replica:0/task:0/device:CPU:0"</span>]()]]
</code></pre>

<h6 id="graph-7">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig5.png" width="300px">


</figure>

<p>…is a terrible example, since it throws an exception. Placeholders 
expect to be given a value. We didn’t supply one, so Tensorflow crashed.</p>

<p>To provide a value, we use the feed_dict attribute of <code>sess.run()</code>.</p>

<h6 id="code-7">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
input_placeholder = tf.placeholder(tf.int32)
sess = tf.Session()
<span class="hljs-keyword">print</span> sess.run(input_placeholder, feed_dict={input_placeholder: <span class="hljs-number">2</span>})
</code></pre>

<h6 id="output-5">Output:</h6>

<pre><code class="language-python hljs"><span class="hljs-number">2</span>
</code></pre>

<h6 id="graph-8">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig5.png" width="300px">


</figure>

<p>Much better. Notice the format of the dict passed into <code>feed_dict</code>. The keys should be variables corresponding to placeholder nodes from the graph (which, as discussed earlier, really means <em>pointers</em>
 to placeholder nodes in the graph). The corresponding values are the 
data elements to assign to each placeholder – typically scalars or Numpy
 arrays.</p>

<h3 id="third-key-abstraction-computation-paths">Third Key Abstraction: Computation Paths</h3>

<p>Let’s try another example involving placeholders:</p>

<h6 id="code-8">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
input_placeholder = tf.placeholder(tf.int32)
three_node = tf.constant(<span class="hljs-number">3</span>)
sum_node = input_placeholder + three_node
sess = tf.Session()
<span class="hljs-keyword">print</span> sess.run(three_node)
<span class="hljs-keyword">print</span> sess.run(sum_node)
</code></pre>

<h6 id="output-6">Output:</h6>

<pre><code class="language-python hljs"><span class="hljs-number">3</span>
Traceback (most recent call last):
...
InvalidArgumentError (see above <span class="hljs-keyword">for</span> traceback): You must feed a value <span class="hljs-keyword">for</span> placeholder tensor <span class="hljs-string">'Placeholder_2'</span> <span class="hljs-keyword">with</span> dtype int32
	 [[Node: Placeholder_2 = Placeholder[dtype=DT_INT32, shape=&lt;unknown&gt;, _device=<span class="hljs-string">"/job:localhost/replica:0/task:0/device:CPU:0"</span>]()]]
</code></pre>

<h6 id="graph-9">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig6.png" width="300px">


</figure>

<p>Why does the second call to <code>sess.run()</code> fail? And why does it raise an error related to <code>input_placeholder</code>, even though we are not evaluating <code>input_placeholder</code>? The answer lies in the final key Tensorflow abstraction: computation paths. Luckily, this one is very intuitive.</p>

<p>When we call <code>sess.run()</code> on a node that is dependent on 
other nodes in the graph, we need to compute the values of those nodes, 
too. And if those nodes have dependencies, we need to calculate those 
values (and so on and so on…) until we reach the “top” of the 
computation graph where nodes have no predecessors.</p>

<p>Consider the computation path of <code>sum_node</code>:</p>

<p></p><figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig7.png" width="300px">


</figure>
<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig8.png" width="300px">


</figure><p></p>

<p>All three nodes need to be evaluated to compute the value of <code>sum_node</code>. Crucially, this includes our un-filled placeholder and explains the exception!</p>

<p>In contrast, consider the computation path of <code>three_node</code>:</p>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig9.png" width="300px">


</figure>

<p>Due to the graph structure, we don’t need to compute all of the nodes
 in order to evaluate the one we want! Because we don’t need to evaluate
 <code>placeholder_node</code> to evaluate <code>three_node</code>, running <code>sess.run(three_node)</code> doesn’t raise an exception.</p>

<p>The fact that Tensorflow automatically routes computation only 
through nodes that are necessary is a huge strength of the framework. It
 saves a lot of runtime on calls if the graph is very big and has many 
nodes that are not necessary. It allows us to construct large, 
“multi-purpose” graphs, which use a single, shared set of core nodes to 
do different things depending on which computation path is taken. For 
almost every application, it’s important to think about <code>sess.run()</code> calls in terms of the computation path taken.</p>

<h3 id="variables-side-effects">Variables &amp; Side Effects</h3>

<p>So far, we’ve seen two types of “no-ancestor” nodes: <code>tf.constant</code>, which is the same for every run, and <code>tf.placeholder</code>, which is different for every run. There’s a third case that we often want to consider: a node which <em>generally</em> has the same value between runs, but can also be updated to have a new value. That’s where variables come in.</p>

<p>Understanding variables is essential to doing deep learning with 
Tensorflow, because the parameters of your model fall into this 
category. During training, you want to update your parameters at every 
step, via gradient descent; but during evaluation, you want to keep your
 parameters fixed, and pass a bunch of different test-set inputs into 
the model. More than likely, all of your model’s trainable parameters 
will be implemented as variables.</p>

<p>To create variables, use <code>tf.get_variable()</code>.<sup class="footnote-ref" id="fnref:2"><a href="#fn:2">3</a></sup> The first two arguments to <code>tf.get_variable()</code> are required; the rest are optional. They are <code>tf.get_variable(name, shape)</code>. <code>name</code>
 is a string which uniquely identifies this variable object. It must be 
unique relative to the global graph, so be careful to keep track of all 
names you have used to ensure there are no duplicates.<sup class="footnote-ref" id="fnref:3"><a href="#fn:3">4</a></sup> <code>shape</code>
 is an array of integers corresponding to the shape of a tensor; the 
syntax of this is intuitive – just one integer per dimension, in order. 
For example, a 3x8 matrix would have shape <code>[3, 8]</code>. To create a scalar, use an empty list as your shape: <code>[]</code>.</p>

<h6 id="code-9">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
count_variable = tf.get_variable(<span class="hljs-string">"count"</span>, [])
sess = tf.Session()
<span class="hljs-keyword">print</span> sess.run(count_variable)
</code></pre>

<h6 id="output-7">Output:</h6>

<pre><code class="language-python hljs">Traceback (most recent call last):
...
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value count
	 [[Node: _retval_count_0_0 = _Retval[T=DT_FLOAT, index=<span class="hljs-number">0</span>, _device=<span class="hljs-string">"/job:localhost/replica:0/task:0/device:CPU:0"</span>](count)]]
</code></pre>

<h6 id="graph-10">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig10.png" width="300px">


</figure>

<p>Alas, another exception. When a variable node is first created, it 
basically stores “null”, and any attempts to evaluate it will result in 
this exception. We can only evaluate a variable after putting a value 
into it first. There are two main ways to put a value into a variable: 
initializers and <code>tf.assign()</code>. Let’s look at <code>tf.assign()</code> first:</p>

<h6 id="code-10">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
count_variable = tf.get_variable(<span class="hljs-string">"count"</span>, [])
zero_node = tf.constant(<span class="hljs-number">0.</span>)
assign_node = tf.assign(count_variable, zero_node)
sess = tf.Session()
sess.run(assign_node)
<span class="hljs-keyword">print</span> sess.run(count_variable)
</code></pre>

<h6 id="output-8">Output:</h6>

<pre><code class="language-python hljs"><span class="hljs-number">0</span>
</code></pre>

<h6 id="graph-11">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig11.png" width="300px">


</figure>

<p><code>tf.assign(target, value)</code> is a node that has some unique properties compared to nodes we’ve seen so far:</p>

<ul>
<li>Identity operation. <code>tf.assign(target, value)</code> does not do any interesting computations, it is always just equal to <code>value</code>.</li>
<li>Side effects. When computation “flows” through <code>assign_node</code>, side effects happen to other things in the graph. In this case, the side effect is to replace the value of <code>count_variable</code> with the value stored in <code>zero_node</code>.</li>
<li>Non-dependent edges. Even though the <code>count_variable</code> node and the <code>assign_node</code>
 are connected in the graph, neither is dependent on the other. This 
means computation will not flow back through that edge when evaluating 
either node. However, <code>assign_node</code> <em>is</em> dependent on <code>zero_node</code>; it needs to know what to assign.</li>
</ul>

<p>“Side effect” nodes underpin most of the Tensorflow deep learning 
workflow, so make sure you really understand what’s going on here. When 
we call <code>sess.run(assign_node)</code>, the computation path goes through <code>assign_node</code> and <code>zero_node</code>.</p>

<h6 id="graph-12">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig12.png" width="300px">


</figure>

<p>As computation flows through any node in the graph, it also enacts 
any side effects controlled by that node, shown in green. Due to the 
particular side effects of <code>tf.assign</code>, the memory associated with <code>count_variable</code> (which was previously “null”) is now permanently set to equal 0. This means that when we next call <code>sess.run(count_variable)</code>, we don’t throw any exceptions. Instead, we get a value of 0. Success!</p>

<p>Next, let’s look at initializers:</p>

<h6 id="code-11">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
const_init_node = tf.constant_initializer(<span class="hljs-number">0.</span>)
count_variable = tf.get_variable(<span class="hljs-string">"count"</span>, [], initializer=const_init_node)
sess = tf.Session()
<span class="hljs-keyword">print</span> sess.run([count_variable])
</code></pre>

<h6 id="output-9">Output:</h6>

<pre><code class="language-python hljs">Traceback (most recent call last):
...
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value count
	 [[Node: _retval_count_0_0 = _Retval[T=DT_FLOAT, index=<span class="hljs-number">0</span>, _device=<span class="hljs-string">"/job:localhost/replica:0/task:0/device:CPU:0"</span>](count)]]
</code></pre>

<h6 id="graph-13">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig13.png" width="300px">


</figure>

<p>Okay, what happened here? Why didn’t the initializer work?</p>

<p>The answer lies in the split between sessions and graphs. We’ve set the <code>initializer</code> property of <code>get_variable</code> to point at our <code>const_init_node</code>, but that just added a new connection between nodes in the graph. We haven’t done anything about the root of the exception: <em>the memory associated with the variable node</em> (which is stored in the session, not the graph!) is still set to “null”. We need the session to tell the <code>const_init_node</code> to actually update the variable.</p>

<h6 id="code-12">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
const_init_node = tf.constant_initializer(<span class="hljs-number">0.</span>)
count_variable = tf.get_variable(<span class="hljs-string">"count"</span>, [], initializer=const_init_node)
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)
<span class="hljs-keyword">print</span> sess.run(count_variable)
</code></pre>

<h6 id="output-10">Output:</h6>

<pre><code class="language-python hljs"><span class="hljs-number">0.</span>
</code></pre>

<h6 id="graph-14">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig14.png" width="300px">


</figure>

<p>To do this, we added another, special node: <code>init = tf.global_variables_initializer()</code>. Similarly to <code>tf.assign()</code>, this is a node with side effects. In contrast to <code>tf.assign()</code>, we don’t actually need to specify what its inputs are! <code>tf.global_variables_initializer()</code> will look at the global graph at the moment of its creation and automatically add dependencies to every <code>tf.initializer</code> in the graph. When we then evaluate it with <code>sess.run(init)</code>, it goes to each of the initializers and tells them to do their thang, initializing the variables and allowing us to run <code>sess.run(count_variable)</code> without an error.</p>

<h4 id="variable-sharing">Variable Sharing</h4>

<p>You may encounter Tensorflow code with variable sharing, which 
involves creating a scope and setting “reuse=True”. I strongly recommend
 that you don’t use this in your own code. If you want to use a single 
variable in multiple places, simply keep track of your pointer to that 
variable’s node programmatically, and re-use it when you need to. In 
other words, you should have only a single call of <code>tf.get_variable()</code> for each parameter you intend to store in memory.</p>

<h3 id="optimizers">Optimizers</h3>

<p>At last: on to the actual deep learning! If you’re still with me, the remaining concepts should be extremely straightforward.</p>

<p>In deep learning, the typical “inner loop” of training is as follows:</p>

<ol>
<li>Get an input and true_output</li>
<li>Compute a “guess” based on the input and your parameters</li>
<li>Compute a “loss” based on the difference between your guess and the true_output</li>
<li>Update the parameters according to the gradient of the loss</li>
</ol>

<p>Let’s put together a quick script for a toy linear regression problem:</p>

<h6 id="code-13">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment">### build the graph</span>
<span class="hljs-comment">## first set up the parameters</span>
m = tf.get_variable(<span class="hljs-string">"m"</span>, [], initializer=tf.constant_initializer(<span class="hljs-number">0.</span>))
b = tf.get_variable(<span class="hljs-string">"b"</span>, [], initializer=tf.constant_initializer(<span class="hljs-number">0.</span>))
init = tf.global_variables_initializer()

<span class="hljs-comment">## then set up the computations</span>
input_placeholder = tf.placeholder(tf.float32)
output_placeholder = tf.placeholder(tf.float32)

x = input_placeholder
y = output_placeholder
y_guess = m * x + b

loss = tf.square(y - y_guess)

<span class="hljs-comment">## finally, set up the optimizer and minimization node</span>
optimizer = tf.train.GradientDescentOptimizer(<span class="hljs-number">1e-3</span>)
train_op = optimizer.minimize(loss)

<span class="hljs-comment">### start the session</span>
sess = tf.Session()
sess.run(init)

<span class="hljs-comment">### perform the training loop</span>
<span class="hljs-keyword">import</span> random

<span class="hljs-comment">## set up problem</span>
true_m = random.random()
true_b = random.random()

<span class="hljs-keyword">for</span> update_i <span class="hljs-keyword">in</span> range(<span class="hljs-number">100000</span>):
  <span class="hljs-comment">## (1) get the input and output</span>
  input_data = random.random()
  output_data = true_m * input_data + true_b

  <span class="hljs-comment">## (2), (3), and (4) all take place within a single call to sess.run()!</span>
  _loss, _ = sess.run([loss, train_op], feed_dict={input_placeholder: input_data, output_placeholder: output_data})
  <span class="hljs-keyword">print</span> update_i, _loss

<span class="hljs-comment">### finally, print out the values we learned for our two variables</span>
<span class="hljs-keyword">print</span> <span class="hljs-string">"True parameters:     m=%.4f, b=%.4f"</span> % (true_m, true_b)
<span class="hljs-keyword">print</span> <span class="hljs-string">"Learned parameters:  m=%.4f, b=%.4f"</span> % tuple(sess.run([m, b]))
</code></pre>

<h6 id="output-11">Output:</h6>

<pre><code class="language-python hljs"><span class="hljs-number">0</span> <span class="hljs-number">2.3205383</span>
<span class="hljs-number">1</span> <span class="hljs-number">0.5792742</span>
<span class="hljs-number">2</span> <span class="hljs-number">1.55254</span>
<span class="hljs-number">3</span> <span class="hljs-number">1.5733259</span>
<span class="hljs-number">4</span> <span class="hljs-number">0.6435648</span>
<span class="hljs-number">5</span> <span class="hljs-number">2.4061265</span>
<span class="hljs-number">6</span> <span class="hljs-number">1.0746256</span>
<span class="hljs-number">7</span> <span class="hljs-number">2.1998715</span>
<span class="hljs-number">8</span> <span class="hljs-number">1.6775116</span>
<span class="hljs-number">9</span> <span class="hljs-number">1.6462423</span>
<span class="hljs-number">10</span> <span class="hljs-number">2.441034</span>
...
<span class="hljs-number">99990</span> <span class="hljs-number">2.9878322e-12</span>
<span class="hljs-number">99991</span> <span class="hljs-number">5.158629e-11</span>
<span class="hljs-number">99992</span> <span class="hljs-number">4.53646e-11</span>
<span class="hljs-number">99993</span> <span class="hljs-number">9.422685e-12</span>
<span class="hljs-number">99994</span> <span class="hljs-number">3.991829e-11</span>
<span class="hljs-number">99995</span> <span class="hljs-number">1.134115e-11</span>
<span class="hljs-number">99996</span> <span class="hljs-number">4.9467985e-11</span>
<span class="hljs-number">99997</span> <span class="hljs-number">1.3219648e-11</span>
<span class="hljs-number">99998</span> <span class="hljs-number">5.684342e-14</span>
<span class="hljs-number">99999</span> <span class="hljs-number">3.007017e-11</span>
<span class="hljs-keyword">True</span> parameters:     m=<span class="hljs-number">0.3519</span>, b=<span class="hljs-number">0.3242</span>
Learned parameters:  m=<span class="hljs-number">0.3519</span>, b=<span class="hljs-number">0.3242</span>
</code></pre>

<p>As you can see, the loss goes down to basically nothing, and we wind 
up with a really good estimate of the true parameters. Hopefully, the 
only part of the code that is new to you is this segment:</p>

<pre><code class="language-python hljs"><span class="hljs-comment">## finally, set up the optimizer and minimization node</span>
optimizer = tf.train.GradientDescentOptimizer(<span class="hljs-number">1e-3</span>)
train_op = optimizer.minimize(loss)
</code></pre>

<p>But, now that you have a good understanding of the concepts 
underlying Tensorflow, this code is easy to explain! The first line, <code>optimizer = tf.train.GradientDescentOptimizer(1e-3)</code>, is not adding a node to the graph. It is simply creating a Python object that has useful helper functions. The second line, <code>train_op = optimizer.minimize(loss)</code>, is adding a node to the graph, and storing a pointer to it in variable <code>train_op</code>. The <code>train_op</code> node has no output, but has a very complicated side effect:</p>

<p><code>train_op</code> traces back through the computation path of its input, <code>loss</code>,
 looking for variable nodes. For each variable node it finds, it 
computes the gradient of the loss with respect to that variable. Then, 
it computes a new value for that variable: the current value minus the 
gradient times the learning rate. Finally, it performs an assign 
operation to update the value of the variable.</p>

<p>So essentially, when we call <code>sess.run(train_op)</code>, it does
 a step of gradient descent on all of our variables for us. Of course, 
we also need to fill in the input and output placeholders with our 
feed_dict, and we also want to print the loss, because it’s handy for 
debugging.</p>

<h3 id="debugging-with-tf-print">Debugging with <code>tf.Print</code></h3>

<p>As you start doing more complicated things with Tensorflow, you’re 
going to want to debug. In general, it’s quite hard to inspect what’s 
going on inside a computation graph. You can’t use a regular Python 
print statement, because you never have access to the values you want to
 print – they are locked away inside the <code>sess.run()</code> call. To elaborate, suppose you want to inspect an intermediate value of a computation. Before the <code>sess.run()</code> call, the intermediate values do not exist yet. But when the <code>sess.run()</code> call returns, the intermediate values are gone!</p>

<p>Let’s look at a simple example.</p>

<h6 id="code-14">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
two_node = tf.constant(<span class="hljs-number">2</span>)
three_node = tf.constant(<span class="hljs-number">3</span>)
sum_node = two_node + three_node
sess = tf.Session()
<span class="hljs-keyword">print</span> sess.run(sum_node)
</code></pre>

<h6 id="output-12">Output:</h6>

<pre><code class="language-python hljs"><span class="hljs-number">5</span>
</code></pre>

<p>This lets us see our overall answer, 5. But what if we want to inspect the intermediate values, <code>two_node</code> and <code>three_node</code>? One way to inspect the intermediate values is to add a return argument to <code>sess.run()</code> that points at each of the intermediate nodes you want to inspect, and then, after it has been returned, print it.</p>

<h6 id="code-15">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
two_node = tf.constant(<span class="hljs-number">2</span>)
three_node = tf.constant(<span class="hljs-number">3</span>)
sum_node = two_node + three_node
sess = tf.Session()
answer, inspection = sess.run([sum_node, [two_node, three_node]])
<span class="hljs-keyword">print</span> inspection
<span class="hljs-keyword">print</span> answer
</code></pre>

<h6 id="output-13">Output:</h6>

<pre><code class="language-python hljs">[<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]
<span class="hljs-number">5</span>
</code></pre>

<p>This often works well, but as code becomes more complex, it can be a bit awkward. A more convenient approach is to use a <code>tf.Print</code> statement. Confusingly, <code>tf.Print</code>
 is actually a type of Tensorflow node, which has both output and side 
effects! It has two required arguments: a node to copy, and a list of 
things to print. The “node to copy” can be any node in the graph; <code>tf.Print</code>
 is an identity operation with respect to its “node to copy”, meaning 
that it outputs an exact copy of its input. But, it also prints all the 
current values in the “list of things to print” as a side effect.<sup class="footnote-ref" id="fnref:4"><a href="#fn:4">5</a></sup></p>

<h6 id="code-16">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
two_node = tf.constant(<span class="hljs-number">2</span>)
three_node = tf.constant(<span class="hljs-number">3</span>)
sum_node = two_node + three_node
print_sum_node = tf.Print(sum_node, [two_node, three_node])
sess = tf.Session()
<span class="hljs-keyword">print</span> sess.run(print_sum_node)
</code></pre>

<h6 id="output-14">Output:</h6>

<pre><code class="language-python hljs">[<span class="hljs-number">2</span>][<span class="hljs-number">3</span>]
<span class="hljs-number">5</span>
</code></pre>

<h6 id="graph-15">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig15.png" width="300px">


</figure>

<p>One important, somewhat-subtle point about <code>tf.Print</code>: printing is a side effect. Like all other side effects, printing only occurs if the computation flows through the <code>tf.Print</code> node. If the <code>tf.Print</code> node is not in the path of the computation, nothing will print. In particular, even if the original node that your <code>tf.Print</code> node is copying is on the computation path, the <code>tf.Print</code>
 node itself might not be. Watch out for this issue! When it strikes 
(and it eventually will), it can be incredibly frustrating if you aren’t
 specifically looking for it. As a general rule, try to always create 
your <code>tf.Print</code> node immediately after creating the node that it copies.</p>

<h6 id="code-17">Code:</h6>

<pre><code class="language-python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
two_node = tf.constant(<span class="hljs-number">2</span>)
three_node = tf.constant(<span class="hljs-number">3</span>)
sum_node = two_node + three_node
<span class="hljs-comment">### this new copy of two_node is not on the computation path, so nothing prints!</span>
print_two_node = tf.Print(two_node, [two_node, three_node, sum_node])
sess = tf.Session()
<span class="hljs-keyword">print</span> sess.run(sum_node)
</code></pre>

<h6 id="output-15">Output:</h6>

<pre><code class="language-python hljs"><span class="hljs-number">5</span>
</code></pre>

<h6 id="graph-16">Graph:</h6>

<figure>

<img src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/fig16.png" width="300px">


</figure>

<p><a href="https://wookayin.github.io/tensorflow-talk-debugging/#1" target="_blank">Here</a> is a great resource which provides additional practical debugging advice.</p>

<h1 id="conclusion">Conclusion</h1>

<p>Hopefully this post helped you get a better intuition for what 
Tensorflow is, how it works, and how to use it. At the end of the day, 
the concepts presented here are fundamental to all Tensorflow programs, 
but this is only scratching the surface. In your Tensorflow adventures, 
you will likely encounter all sorts of other fun things that you want to
 use: conditionals, iteration, distributed Tensorflow, variable scopes, 
saving &amp; loading models, multi-graph, multi-session, and multi-core,
 data-loader queues, and much more. Many of these topics I will cover in
 future posts. But if you build on the ideas you learned here with the 
official documentation, some code examples, and just a pinch of deep 
learning magic, I’m sure you’ll be able to figure it out!</p>

<p>For more detail on how these abstractions are implemented in Tensorflow, and how to interact with them, take a look at my <a href="https://jacobbuckman.com/post/graph-inspection/" target="_blank">post on inspecting computational graphs</a>.</p>

<p>Please give me feedback in the comments (or via email) if anything 
discussed in this guide was unclear. And if you enjoyed this post, let 
me know what I should cover next!</p>

<p>Happy training!</p>

<p><em>This post is the first of a series; click <a href="https://jacobbuckman.com/post/tensorflow-the-confusing-parts-2/" target="_blank">here</a> for the next post, or <a href="https://jacobbuckman.com/categories/tftcp/" target="_blank">here</a> for a list of all posts in this series.</em></p>

<p><em>Many thanks to Kathryn Rough, Katherine Lee, Sara Hooker, and 
Ludwig Schubert for all of their help and feedback when writing this 
post.</em></p>
<div class="footnotes">

<hr>

<ol>
<li id="fn:0"><a href="https://docs.chainer.org/en/stable/guides/define_by_run.html" target="_blank">This page</a> from the Chainer documentation describes the difference between define-and-run and define-by-run.
 <a class="footnote-return" href="#fnref:0"><sup>^</sup></a></li>
<li id="fn:1">In general, I prefer to make sure I already have the 
entire graph in place when I create a session, and I follow that 
paradigm in my examples here. But you might see it done differently in 
other Tensorflow code.
 <a class="footnote-return" href="#fnref:1"><sup>^</sup></a></li>
<li id="fn:2">Since the Tensorflow team is dedicated to backwards 
compatibility, there are several ways to create variables. In older 
code, it is common to also encounter the <code>tf.Variable()</code> syntax, which serves the same purpose.
 <a class="footnote-return" href="#fnref:2"><sup>^</sup></a></li>
<li id="fn:3">Name management can be made a bit easier with <code>tf.variable_scope()</code>. I will cover scoping in more detail In a future post!
 <a class="footnote-return" href="#fnref:3"><sup>^</sup></a></li>
<li id="fn:4">Note that <code>tf.Print</code> is not compatible with 
Colab or IPython notebooks; it prints to the standard output, which is 
not shown in the notebook. There are various solutions on StackOverflow.
 <a class="footnote-return" href="#fnref:4"><sup>^</sup></a></li>
</ol>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="label label-default" href="https://jacobbuckman.com/tags/tensorflow/">Tensorflow</a>
  
</div>




    
    

    

    
<section id="comments">
  <div id="disqus_thread"><iframe id="dsq-app2765" name="dsq-app2765" allowtransparency="true" scrolling="no" tabindex="0" title="Disqus" style="width: 1px !important; min-width: 100% !important; border: medium none !important; overflow: hidden !important; height: 2992px !important;" src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/a.htm" horizontalscrolling="no" verticalscrolling="no" width="100%" frameborder="0"></iframe></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "jacobbuckman" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="<a class="vglnk" href="https://disqus.com/?ref_noscript" rel="nofollow"><span>https</span><span>://</span><span>disqus</span><span>.</span><span>com</span><span>/?</span><span>ref</span><span>_</span><span>noscript</span></a>">comments powered by Disqus.</a></noscript>

</section>



  </div>
</article>

<footer class="site-footer">
  <div class="container">

    

    <p class="powered-by">

      © 2018 · 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">×</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script type="text/x-mathjax-config;executed=true">
      MathJax.Hub.Config({
        CommonHTML: { linebreaks: { automatic: true } },
        tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
        TeX: { noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } } },
        messageStyle: 'none'
      });
    </script>
    

    
    
    
      <script src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/jquery_002.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
      <script src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/imagesloaded.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/bootstrap.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
      <script src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/isotope.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/jquery.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/highlight.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
        <script src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/python.js"></script>
        
      

      
      
      <script src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/MathJax.js" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async=""></script>
      
    

    <script src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/hugo-academic.js"></script>
    

    
    

    
    
    
    <script id="dsq-count-scr" src="Tensorflow%20%20The%20Confusing%20Parts%20(1)%20%20%20Buckman's%20Homepage_files/count.js" async=""></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    

  


<iframe style="display: none;"></iframe></body></html>